{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import os,PIL,pathlib\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'test']\n"
     ]
    }
   ],
   "source": [
    "import os,PIL,random,pathlib\n",
    "\n",
    "data_dir = '.'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "data_paths  = list(data_dir.glob('*'))\n",
    "#classeNames = [str(path).split(\"\\\\\")[1] for path in data_paths]\n",
    "#classeName  = [str(path) for path in data_paths]\n",
    "classeNames = [\"train\",\"test\"]\n",
    "print(classeNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关于transforms.Compose的更多介绍可以参考：https://blog.csdn.net/qq_38251616/article/details/124878863\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),  # 将输入图片resize成统一尺寸\n",
    "    # transforms.RandomHorizontalFlip(), # 随机水平翻转\n",
    "    transforms.ToTensor(),          # 将PIL Image或numpy.ndarray转换为tensor，并归一化到[0,1]之间\n",
    "    transforms.Normalize(           # 标准化处理-->转换为标准正太分布（高斯分布），使模型更容易收敛\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225])  # 其中 mean=[0.485,0.456,0.406]与std=[0.229,0.224,0.225] 从数据集中随机抽样计算得到的。\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),  # 将输入图片resize成统一尺寸\n",
    "    transforms.ToTensor(),          # 将PIL Image或numpy.ndarray转换为tensor，并归一化到[0,1]之间\n",
    "    transforms.Normalize(           # 标准化处理-->转换为标准正太分布（高斯分布），使模型更容易收敛\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225])  # 其中 mean=[0.485,0.456,0.406]与std=[0.229,0.224,0.225] 从数据集中随机抽样计算得到的。\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"F:/github/deep_learning_prj/intro_deeplearning_project/P5/5-data/train/\",transform=train_transforms)\n",
    "test_dataset  = datasets.ImageFolder(\"F:/github/deep_learning_prj/intro_deeplearning_project/P5/5-data/test/\",transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([32, 3, 224, 224])\n",
      "Shape of y:  torch.Size([32]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dl:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(12, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (pool3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(12, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (pool6): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dropout): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=60000, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(3, 12, kernel_size=5, padding=0), # 12*220*220\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=0), # 12*216*216\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.pool3=nn.Sequential(\n",
    "            nn.MaxPool2d(2))                              # 12*108*108\n",
    "        \n",
    "        self.conv4=nn.Sequential(\n",
    "            nn.Conv2d(12, 24, kernel_size=5, padding=0), # 24*104*104\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv5=nn.Sequential(\n",
    "            nn.Conv2d(24, 24, kernel_size=5, padding=0), # 24*100*100\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.pool6=nn.Sequential(\n",
    "            nn.MaxPool2d(2))                              # 24*50*50\n",
    "\n",
    "        self.dropout = nn.Sequential(\n",
    "            nn.Dropout(0.2))\n",
    "        \n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(24*50*50, len(classeNames)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print('X',x)\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv1(x)  # 卷积-BN-激活\n",
    "        x = self.conv2(x)  # 卷积-BN-激活\n",
    "        x = self.pool3(x)  # 池化\n",
    "        x = self.conv4(x)  # 卷积-BN-激活\n",
    "        x = self.conv5(x)  # 卷积-BN-激活\n",
    "        x = self.pool6(x)  # 池化\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(batch_size, -1)  # flatten 变成全连接网络需要的输入 (batch, 24*50*50) ==> (batch, -1), -1 此处自动算出的是24*50*50\n",
    "        #print('X',x)\n",
    "        x = self.fc(x)\n",
    "        #print('X after',x)\n",
    "        return x\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "model = Model().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)  # 训练集的大小\n",
    "    num_batches = len(dataloader)   # 批次数目, (size/batch_size，向上取整)\n",
    "\n",
    "    train_loss, train_acc = 0, 0  # 初始化训练损失和正确率\n",
    "    \n",
    "    for X, y in dataloader:  # 获取图片及其标签\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        #print(\"X\",X)\n",
    "        #print(\"X shape\",X.shape)\n",
    "        # 计算预测误差\n",
    "        pred = model(X)          # 网络输出\n",
    "        print(\"pred\",pred)\n",
    "        print(\"pred shape\",pred.shape)\n",
    "        print(\"y\",y)\n",
    "        #loss = loss_fn(pred, y)  # 计算网络输出和真实值之间的差距，targets为真实值，计算二者差值即为损失\n",
    "        \n",
    "        # 反向传播\n",
    "        #optimizer.zero_grad()  # grad属性归零\n",
    "        #loss.backward()        # 反向传播\n",
    "        #optimizer.step()       # 每一步自动更新\n",
    "        \n",
    "        # 记录acc与loss\n",
    "        #train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        #train_loss += loss.item()\n",
    "            \n",
    "    train_acc  /= size\n",
    "    train_loss /= num_batches\n",
    "\n",
    "    return train_acc, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (dataloader, model, loss_fn):\n",
    "    size        = len(dataloader.dataset)  # 测试集的大小\n",
    "    num_batches = len(dataloader)          # 批次数目, (size/batch_size，向上取整)\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # 当不进行训练时，停止梯度更新，节省计算内存消耗\n",
    "    with torch.no_grad():\n",
    "        for imgs, target in dataloader:\n",
    "            imgs, target = imgs.to(device), target.to(device)\n",
    "            \n",
    "            # 计算loss\n",
    "            target_pred = model(imgs)\n",
    "            loss        = loss_fn(target_pred, target)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "\n",
    "    test_acc  /= size\n",
    "    test_loss /= num_batches\n",
    "\n",
    "    return test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, start_lr):\n",
    "    # 每 2 个epoch衰减到原来的 0.92\n",
    "    lr = start_lr * (0.92 ** (epoch // 2))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "learn_rate = 1e-4 # 初始学习率\n",
    "optimizer  = torch.optim.SGD(model.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0610],\n",
      "        [0.4381, 0.4694, 0.4833,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0535, 0.0535, 0.0535],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1899, 0.1899, 0.1899],\n",
      "        [0.8930, 1.4474, 1.8887,  ..., 1.3066, 0.0000, 1.4843],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0535, 0.0535, 0.0535]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[ 0.4176,  0.6134],\n",
      "        [ 0.6408,  1.0982],\n",
      "        [ 0.1288, -0.3696],\n",
      "        [-0.4573, -0.1214],\n",
      "        [-0.0750, -0.5709],\n",
      "        [ 0.4356, -0.6465],\n",
      "        [-0.1256, -0.4215],\n",
      "        [ 0.5221, -0.6858],\n",
      "        [ 0.1888, -0.0273],\n",
      "        [ 0.3198,  0.6188],\n",
      "        [ 0.3037,  0.6195],\n",
      "        [-0.1351,  0.4675],\n",
      "        [-1.0340, -0.6852],\n",
      "        [-0.0818,  0.3315],\n",
      "        [-0.1360, -0.2077],\n",
      "        [ 0.2709,  0.1698],\n",
      "        [ 0.0673,  0.3865],\n",
      "        [ 0.6391,  0.4208],\n",
      "        [ 0.0787, -0.1783],\n",
      "        [-0.0986,  0.0126],\n",
      "        [ 0.2199, -0.3240],\n",
      "        [-0.1876,  0.1954],\n",
      "        [-0.5635,  0.0912],\n",
      "        [ 0.7803,  0.6840],\n",
      "        [ 0.1846,  0.5306],\n",
      "        [-2.3595,  1.2424],\n",
      "        [-0.3227,  0.9155],\n",
      "        [ 0.6992,  0.4723],\n",
      "        [-0.0953,  0.4612],\n",
      "        [ 0.7155,  0.4499],\n",
      "        [-0.3378,  0.1327],\n",
      "        [ 0.3865,  0.0824]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[ 0.4176,  0.6134],\n",
      "        [ 0.6408,  1.0982],\n",
      "        [ 0.1288, -0.3696],\n",
      "        [-0.4573, -0.1214],\n",
      "        [-0.0750, -0.5709],\n",
      "        [ 0.4356, -0.6465],\n",
      "        [-0.1256, -0.4215],\n",
      "        [ 0.5221, -0.6858],\n",
      "        [ 0.1888, -0.0273],\n",
      "        [ 0.3198,  0.6188],\n",
      "        [ 0.3037,  0.6195],\n",
      "        [-0.1351,  0.4675],\n",
      "        [-1.0340, -0.6852],\n",
      "        [-0.0818,  0.3315],\n",
      "        [-0.1360, -0.2077],\n",
      "        [ 0.2709,  0.1698],\n",
      "        [ 0.0673,  0.3865],\n",
      "        [ 0.6391,  0.4208],\n",
      "        [ 0.0787, -0.1783],\n",
      "        [-0.0986,  0.0126],\n",
      "        [ 0.2199, -0.3240],\n",
      "        [-0.1876,  0.1954],\n",
      "        [-0.5635,  0.0912],\n",
      "        [ 0.7803,  0.6840],\n",
      "        [ 0.1846,  0.5306],\n",
      "        [-2.3595,  1.2424],\n",
      "        [-0.3227,  0.9155],\n",
      "        [ 0.6992,  0.4723],\n",
      "        [-0.0953,  0.4612],\n",
      "        [ 0.7155,  0.4499],\n",
      "        [-0.3378,  0.1327],\n",
      "        [ 0.3865,  0.0824]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 0, 0])\n",
      "X tensor([[0.0000, 1.0503, 0.8622,  ..., 0.0000, 0.0000, 0.7420],\n",
      "        [0.4301, 0.8264, 1.1899,  ..., 0.0000, 0.0521, 0.0399],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1987, 0.0195],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2038, 0.2025, 0.2025],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0191, 0.0000, 0.0000]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[ 0.4507, -0.2516],\n",
      "        [ 0.5020,  0.0384],\n",
      "        [ 0.0917, -0.1634],\n",
      "        [ 0.8279, -0.5069],\n",
      "        [ 0.1096,  0.2977],\n",
      "        [ 0.4919, -0.2617],\n",
      "        [ 0.2522, -0.3349],\n",
      "        [ 0.5981,  0.3107],\n",
      "        [-0.1215,  0.0039],\n",
      "        [ 0.6311,  0.6323],\n",
      "        [-0.1287, -0.4012],\n",
      "        [ 0.7425,  0.3508],\n",
      "        [ 0.6605,  0.0524],\n",
      "        [-0.6530, -0.8278],\n",
      "        [ 0.4535,  1.0163],\n",
      "        [-0.3168, -0.3142],\n",
      "        [ 0.2122, -0.0655],\n",
      "        [-0.0101,  1.5807],\n",
      "        [-1.3194, -0.1535],\n",
      "        [ 0.0207, -0.1138],\n",
      "        [ 0.5593, -0.5809],\n",
      "        [-0.0995, -0.7330],\n",
      "        [ 0.4249, -0.3067],\n",
      "        [-0.1428,  0.5151],\n",
      "        [-0.1217,  0.4133],\n",
      "        [-0.0398,  0.2766],\n",
      "        [ 0.2686,  0.3011],\n",
      "        [ 0.4706,  0.1502],\n",
      "        [-0.6284, -0.1213],\n",
      "        [-0.6926,  1.3830],\n",
      "        [-0.1035, -0.0077],\n",
      "        [ 0.3171, -0.2694]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[ 0.4507, -0.2516],\n",
      "        [ 0.5020,  0.0384],\n",
      "        [ 0.0917, -0.1634],\n",
      "        [ 0.8279, -0.5069],\n",
      "        [ 0.1096,  0.2977],\n",
      "        [ 0.4919, -0.2617],\n",
      "        [ 0.2522, -0.3349],\n",
      "        [ 0.5981,  0.3107],\n",
      "        [-0.1215,  0.0039],\n",
      "        [ 0.6311,  0.6323],\n",
      "        [-0.1287, -0.4012],\n",
      "        [ 0.7425,  0.3508],\n",
      "        [ 0.6605,  0.0524],\n",
      "        [-0.6530, -0.8278],\n",
      "        [ 0.4535,  1.0163],\n",
      "        [-0.3168, -0.3142],\n",
      "        [ 0.2122, -0.0655],\n",
      "        [-0.0101,  1.5807],\n",
      "        [-1.3194, -0.1535],\n",
      "        [ 0.0207, -0.1138],\n",
      "        [ 0.5593, -0.5809],\n",
      "        [-0.0995, -0.7330],\n",
      "        [ 0.4249, -0.3067],\n",
      "        [-0.1428,  0.5151],\n",
      "        [-0.1217,  0.4133],\n",
      "        [-0.0398,  0.2766],\n",
      "        [ 0.2686,  0.3011],\n",
      "        [ 0.4706,  0.1502],\n",
      "        [-0.6284, -0.1213],\n",
      "        [-0.6926,  1.3830],\n",
      "        [-0.1035, -0.0077],\n",
      "        [ 0.3171, -0.2694]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1])\n",
      "X tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1929, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2529, 2.5220,  ..., 1.4776, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2272, 0.2344, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 2.6090, 0.0000,  ..., 1.1824, 1.1456, 1.1544],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.6775, 0.0000, 1.6052],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0919, 0.0919, 0.0919]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[-2.5627e-01, -1.0006e-01],\n",
      "        [ 7.8987e-01, -8.8381e-01],\n",
      "        [ 2.9140e-01,  1.8541e-01],\n",
      "        [-3.3118e-02,  5.6252e-01],\n",
      "        [ 3.5735e-01, -6.2427e-01],\n",
      "        [ 6.4807e-01,  3.0369e-01],\n",
      "        [ 9.8485e-01,  6.1926e-01],\n",
      "        [ 6.2602e-01,  1.6656e-01],\n",
      "        [ 1.4383e-01,  5.5216e-01],\n",
      "        [ 3.8629e-01, -8.0209e-02],\n",
      "        [-3.3781e-01, -3.0693e-02],\n",
      "        [-8.2773e-01, -4.0202e-01],\n",
      "        [-3.7736e-01, -8.1849e-01],\n",
      "        [ 2.8065e-01, -4.8298e-01],\n",
      "        [-5.8252e-01, -2.5474e-01],\n",
      "        [-5.1637e-04, -1.5936e+00],\n",
      "        [ 2.5705e-01, -8.6224e-01],\n",
      "        [-1.6372e-01, -3.9215e-01],\n",
      "        [-1.3105e-01, -1.4323e-02],\n",
      "        [-2.2977e-01, -4.8006e-01],\n",
      "        [ 6.0951e-01, -2.9025e-01],\n",
      "        [-3.2978e-01, -2.3180e-01],\n",
      "        [-4.5246e-01,  2.1092e-01],\n",
      "        [ 4.6608e-01, -6.3270e-01],\n",
      "        [-2.9386e-01,  1.8999e-02],\n",
      "        [-8.6243e-01, -4.9648e-01],\n",
      "        [ 1.2697e+00, -3.4586e-01],\n",
      "        [ 2.5879e-01,  5.0632e-01],\n",
      "        [ 8.8172e-01, -2.6374e-01],\n",
      "        [ 7.9304e-02, -4.8294e-02],\n",
      "        [-7.2568e-01,  6.1421e-01],\n",
      "        [ 4.0511e-01, -9.3723e-03]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[-2.5627e-01, -1.0006e-01],\n",
      "        [ 7.8987e-01, -8.8381e-01],\n",
      "        [ 2.9140e-01,  1.8541e-01],\n",
      "        [-3.3118e-02,  5.6252e-01],\n",
      "        [ 3.5735e-01, -6.2427e-01],\n",
      "        [ 6.4807e-01,  3.0369e-01],\n",
      "        [ 9.8485e-01,  6.1926e-01],\n",
      "        [ 6.2602e-01,  1.6656e-01],\n",
      "        [ 1.4383e-01,  5.5216e-01],\n",
      "        [ 3.8629e-01, -8.0209e-02],\n",
      "        [-3.3781e-01, -3.0693e-02],\n",
      "        [-8.2773e-01, -4.0202e-01],\n",
      "        [-3.7736e-01, -8.1849e-01],\n",
      "        [ 2.8065e-01, -4.8298e-01],\n",
      "        [-5.8252e-01, -2.5474e-01],\n",
      "        [-5.1637e-04, -1.5936e+00],\n",
      "        [ 2.5705e-01, -8.6224e-01],\n",
      "        [-1.6372e-01, -3.9215e-01],\n",
      "        [-1.3105e-01, -1.4323e-02],\n",
      "        [-2.2977e-01, -4.8006e-01],\n",
      "        [ 6.0951e-01, -2.9025e-01],\n",
      "        [-3.2978e-01, -2.3180e-01],\n",
      "        [-4.5246e-01,  2.1092e-01],\n",
      "        [ 4.6608e-01, -6.3270e-01],\n",
      "        [-2.9386e-01,  1.8999e-02],\n",
      "        [-8.6243e-01, -4.9648e-01],\n",
      "        [ 1.2697e+00, -3.4586e-01],\n",
      "        [ 2.5879e-01,  5.0632e-01],\n",
      "        [ 8.8172e-01, -2.6374e-01],\n",
      "        [ 7.9304e-02, -4.8294e-02],\n",
      "        [-7.2568e-01,  6.1421e-01],\n",
      "        [ 4.0511e-01, -9.3723e-03]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1])\n",
      "X tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4187, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1208, 0.0097, 0.0326],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1260, 0.1610, 0.1437],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0842, 0.0842, 0.0842],\n",
      "        [1.1784, 1.8700, 1.4445,  ..., 0.0000, 0.4619, 0.5465]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[-0.2050, -0.4217],\n",
      "        [ 0.1347, -0.0645],\n",
      "        [-0.0632,  0.5814],\n",
      "        [ 0.2568,  0.1522],\n",
      "        [ 1.0228,  0.2963],\n",
      "        [-0.6472,  0.3977],\n",
      "        [-0.4329, -0.0735],\n",
      "        [-0.2245,  0.2488],\n",
      "        [ 0.4412, -0.5865],\n",
      "        [-0.2490,  0.4055],\n",
      "        [-0.9323,  0.4576],\n",
      "        [-1.0705,  0.2443],\n",
      "        [ 0.0711, -0.0704],\n",
      "        [-0.3192,  0.0133],\n",
      "        [ 1.0250,  0.3417],\n",
      "        [ 1.0592, -0.2922],\n",
      "        [ 0.4574,  0.2302],\n",
      "        [-0.0171, -0.0924],\n",
      "        [ 0.1643,  1.0690],\n",
      "        [ 0.7647,  0.5146],\n",
      "        [ 0.0366, -0.1146],\n",
      "        [ 0.1223,  0.7025],\n",
      "        [ 0.2518, -0.4761],\n",
      "        [ 0.2565,  0.9969],\n",
      "        [-0.1568, -0.2593],\n",
      "        [ 0.2999,  0.1061],\n",
      "        [ 0.0417,  0.4016],\n",
      "        [ 1.5459,  0.3625],\n",
      "        [ 0.3928,  0.4211],\n",
      "        [ 0.4253, -0.4880],\n",
      "        [ 0.0722, -0.6149],\n",
      "        [ 0.4830,  0.7798]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[-0.2050, -0.4217],\n",
      "        [ 0.1347, -0.0645],\n",
      "        [-0.0632,  0.5814],\n",
      "        [ 0.2568,  0.1522],\n",
      "        [ 1.0228,  0.2963],\n",
      "        [-0.6472,  0.3977],\n",
      "        [-0.4329, -0.0735],\n",
      "        [-0.2245,  0.2488],\n",
      "        [ 0.4412, -0.5865],\n",
      "        [-0.2490,  0.4055],\n",
      "        [-0.9323,  0.4576],\n",
      "        [-1.0705,  0.2443],\n",
      "        [ 0.0711, -0.0704],\n",
      "        [-0.3192,  0.0133],\n",
      "        [ 1.0250,  0.3417],\n",
      "        [ 1.0592, -0.2922],\n",
      "        [ 0.4574,  0.2302],\n",
      "        [-0.0171, -0.0924],\n",
      "        [ 0.1643,  1.0690],\n",
      "        [ 0.7647,  0.5146],\n",
      "        [ 0.0366, -0.1146],\n",
      "        [ 0.1223,  0.7025],\n",
      "        [ 0.2518, -0.4761],\n",
      "        [ 0.2565,  0.9969],\n",
      "        [-0.1568, -0.2593],\n",
      "        [ 0.2999,  0.1061],\n",
      "        [ 0.0417,  0.4016],\n",
      "        [ 1.5459,  0.3625],\n",
      "        [ 0.3928,  0.4211],\n",
      "        [ 0.4253, -0.4880],\n",
      "        [ 0.0722, -0.6149],\n",
      "        [ 0.4830,  0.7798]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0])\n",
      "X tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0535, 0.0481, 0.0539],\n",
      "        [0.2389, 0.2279, 0.2515,  ..., 0.1040, 0.1502, 0.0238],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1821, 0.1739, 0.1661],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3235, 0.3381, 0.3395,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[-0.3084, -0.3093],\n",
      "        [ 0.3734,  0.2979],\n",
      "        [ 0.1025, -0.2786],\n",
      "        [-0.8891, -0.0355],\n",
      "        [-0.2270,  0.0764],\n",
      "        [ 0.3039,  0.0614],\n",
      "        [ 0.2489, -0.3773],\n",
      "        [-0.1680, -0.2009],\n",
      "        [ 0.2507, -0.6077],\n",
      "        [ 0.0763,  0.1873],\n",
      "        [ 0.4461, -1.1037],\n",
      "        [ 1.2692, -0.1763],\n",
      "        [ 0.0037, -0.5183],\n",
      "        [ 0.4489, -0.4754],\n",
      "        [-0.0206,  0.1710],\n",
      "        [ 0.6891,  0.3396],\n",
      "        [ 0.4847, -0.7536],\n",
      "        [ 1.1999,  0.7846],\n",
      "        [ 0.7451,  1.0035],\n",
      "        [ 0.2112, -0.1682],\n",
      "        [ 0.2831,  0.0472],\n",
      "        [ 0.2150, -0.6678],\n",
      "        [ 0.1356,  0.0234],\n",
      "        [-0.3690,  0.5085],\n",
      "        [ 0.1626,  0.4829],\n",
      "        [-0.3922,  0.0285],\n",
      "        [-0.1117,  0.3016],\n",
      "        [ 1.1393,  0.2524],\n",
      "        [-0.2945, -0.1961],\n",
      "        [-0.1056,  0.9975],\n",
      "        [-0.5992, -0.3213],\n",
      "        [ 0.8443,  1.4949]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[-0.3084, -0.3093],\n",
      "        [ 0.3734,  0.2979],\n",
      "        [ 0.1025, -0.2786],\n",
      "        [-0.8891, -0.0355],\n",
      "        [-0.2270,  0.0764],\n",
      "        [ 0.3039,  0.0614],\n",
      "        [ 0.2489, -0.3773],\n",
      "        [-0.1680, -0.2009],\n",
      "        [ 0.2507, -0.6077],\n",
      "        [ 0.0763,  0.1873],\n",
      "        [ 0.4461, -1.1037],\n",
      "        [ 1.2692, -0.1763],\n",
      "        [ 0.0037, -0.5183],\n",
      "        [ 0.4489, -0.4754],\n",
      "        [-0.0206,  0.1710],\n",
      "        [ 0.6891,  0.3396],\n",
      "        [ 0.4847, -0.7536],\n",
      "        [ 1.1999,  0.7846],\n",
      "        [ 0.7451,  1.0035],\n",
      "        [ 0.2112, -0.1682],\n",
      "        [ 0.2831,  0.0472],\n",
      "        [ 0.2150, -0.6678],\n",
      "        [ 0.1356,  0.0234],\n",
      "        [-0.3690,  0.5085],\n",
      "        [ 0.1626,  0.4829],\n",
      "        [-0.3922,  0.0285],\n",
      "        [-0.1117,  0.3016],\n",
      "        [ 1.1393,  0.2524],\n",
      "        [-0.2945, -0.1961],\n",
      "        [-0.1056,  0.9975],\n",
      "        [-0.5992, -0.3213],\n",
      "        [ 0.8443,  1.4949]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1])\n",
      "X tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1062],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1015, 0.1015, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1329, 0.1329],\n",
      "        ...,\n",
      "        [0.3199, 0.2464, 0.0000,  ..., 0.0000, 0.0000, 0.0070],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1194, 0.1057, 0.1099],\n",
      "        [0.2265, 0.1600, 0.1698,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[ 0.2783, -0.0659],\n",
      "        [-0.4020, -0.6395],\n",
      "        [-0.5931, -0.2935],\n",
      "        [ 0.6053, -0.2192],\n",
      "        [ 0.3381,  0.8144],\n",
      "        [ 2.1476, -0.6670],\n",
      "        [ 0.5993, -0.4823],\n",
      "        [ 0.5567,  0.9973],\n",
      "        [ 0.3581, -0.2979],\n",
      "        [ 0.1253,  0.3143],\n",
      "        [ 0.1404,  1.2694],\n",
      "        [-0.5699,  0.1534],\n",
      "        [ 0.1438, -0.5811],\n",
      "        [ 0.2397,  0.5933],\n",
      "        [ 0.3993,  0.1648],\n",
      "        [-0.0559, -0.2559],\n",
      "        [ 0.3069, -0.2876],\n",
      "        [-0.0134,  0.5405],\n",
      "        [ 0.7447,  0.0361],\n",
      "        [ 0.8464,  0.5736],\n",
      "        [ 0.0412,  0.6594],\n",
      "        [-0.0506,  0.6116],\n",
      "        [-0.0579, -0.3303],\n",
      "        [ 0.3079,  0.8643],\n",
      "        [ 0.0822,  0.3726],\n",
      "        [ 0.0499,  0.0253],\n",
      "        [ 0.5588,  0.5588],\n",
      "        [-0.3639,  2.0963],\n",
      "        [ 0.2130,  0.8427],\n",
      "        [-1.1799, -0.9687],\n",
      "        [ 0.2007, -0.1651],\n",
      "        [ 0.7019, -0.4117]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[ 0.2783, -0.0659],\n",
      "        [-0.4020, -0.6395],\n",
      "        [-0.5931, -0.2935],\n",
      "        [ 0.6053, -0.2192],\n",
      "        [ 0.3381,  0.8144],\n",
      "        [ 2.1476, -0.6670],\n",
      "        [ 0.5993, -0.4823],\n",
      "        [ 0.5567,  0.9973],\n",
      "        [ 0.3581, -0.2979],\n",
      "        [ 0.1253,  0.3143],\n",
      "        [ 0.1404,  1.2694],\n",
      "        [-0.5699,  0.1534],\n",
      "        [ 0.1438, -0.5811],\n",
      "        [ 0.2397,  0.5933],\n",
      "        [ 0.3993,  0.1648],\n",
      "        [-0.0559, -0.2559],\n",
      "        [ 0.3069, -0.2876],\n",
      "        [-0.0134,  0.5405],\n",
      "        [ 0.7447,  0.0361],\n",
      "        [ 0.8464,  0.5736],\n",
      "        [ 0.0412,  0.6594],\n",
      "        [-0.0506,  0.6116],\n",
      "        [-0.0579, -0.3303],\n",
      "        [ 0.3079,  0.8643],\n",
      "        [ 0.0822,  0.3726],\n",
      "        [ 0.0499,  0.0253],\n",
      "        [ 0.5588,  0.5588],\n",
      "        [-0.3639,  2.0963],\n",
      "        [ 0.2130,  0.8427],\n",
      "        [-1.1799, -0.9687],\n",
      "        [ 0.2007, -0.1651],\n",
      "        [ 0.7019, -0.4117]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1])\n",
      "X tensor([[4.7719, 1.6972, 0.0000,  ..., 1.3538, 0.0000, 1.5534],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1140, 0.1140, 0.1140],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.6257, 2.0485],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1140, 0.1140, 0.1140]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[-0.5550,  0.1510],\n",
      "        [ 0.3161, -0.1341],\n",
      "        [-0.5152, -0.1575],\n",
      "        [-0.4765, -0.2998],\n",
      "        [ 0.1526,  0.4358],\n",
      "        [-0.8656,  0.1514],\n",
      "        [-0.5003,  0.5401],\n",
      "        [ 0.0964, -0.1119],\n",
      "        [ 0.4120,  0.0844],\n",
      "        [-0.4285,  0.0673],\n",
      "        [ 0.2969,  0.2669],\n",
      "        [ 0.2776, -0.1257],\n",
      "        [ 1.2086,  0.2277],\n",
      "        [-0.1170,  0.6859],\n",
      "        [ 0.0857, -0.2322],\n",
      "        [-0.3002, -0.1827],\n",
      "        [-0.3029, -0.5035],\n",
      "        [ 1.0292, -0.0087],\n",
      "        [-0.3918,  0.2160],\n",
      "        [ 0.4137,  0.6202],\n",
      "        [ 0.1003,  0.0583],\n",
      "        [ 0.4912, -0.9390],\n",
      "        [ 0.1257,  0.0428],\n",
      "        [ 0.3096,  0.1370],\n",
      "        [-0.2228, -0.0891],\n",
      "        [-0.8210,  0.5041],\n",
      "        [-0.3106,  0.0314],\n",
      "        [-0.6528,  0.4900],\n",
      "        [ 0.2233,  0.2994],\n",
      "        [ 0.1705,  0.5426],\n",
      "        [-0.1265,  0.7517],\n",
      "        [ 0.5311,  1.0868]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[-0.5550,  0.1510],\n",
      "        [ 0.3161, -0.1341],\n",
      "        [-0.5152, -0.1575],\n",
      "        [-0.4765, -0.2998],\n",
      "        [ 0.1526,  0.4358],\n",
      "        [-0.8656,  0.1514],\n",
      "        [-0.5003,  0.5401],\n",
      "        [ 0.0964, -0.1119],\n",
      "        [ 0.4120,  0.0844],\n",
      "        [-0.4285,  0.0673],\n",
      "        [ 0.2969,  0.2669],\n",
      "        [ 0.2776, -0.1257],\n",
      "        [ 1.2086,  0.2277],\n",
      "        [-0.1170,  0.6859],\n",
      "        [ 0.0857, -0.2322],\n",
      "        [-0.3002, -0.1827],\n",
      "        [-0.3029, -0.5035],\n",
      "        [ 1.0292, -0.0087],\n",
      "        [-0.3918,  0.2160],\n",
      "        [ 0.4137,  0.6202],\n",
      "        [ 0.1003,  0.0583],\n",
      "        [ 0.4912, -0.9390],\n",
      "        [ 0.1257,  0.0428],\n",
      "        [ 0.3096,  0.1370],\n",
      "        [-0.2228, -0.0891],\n",
      "        [-0.8210,  0.5041],\n",
      "        [-0.3106,  0.0314],\n",
      "        [-0.6528,  0.4900],\n",
      "        [ 0.2233,  0.2994],\n",
      "        [ 0.1705,  0.5426],\n",
      "        [-0.1265,  0.7517],\n",
      "        [ 0.5311,  1.0868]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1])\n",
      "X tensor([[0.0000, 0.0000, 0.0000,  ..., 0.8761, 0.8100, 0.5406],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0719, 0.0719, 0.0719],\n",
      "        [1.1973, 0.0000, 1.0987,  ..., 0.0000, 0.0000, 1.2277],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.6374, 0.0000, 0.3469,  ..., 0.2110, 0.1642, 0.0933],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0719, 0.0719, 0.0719]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[ 0.3489, -0.2584],\n",
      "        [ 0.7827,  1.3279],\n",
      "        [ 0.5237,  1.7052],\n",
      "        [-0.0142,  0.2398],\n",
      "        [-0.2829, -1.0727],\n",
      "        [-0.0375,  0.4571],\n",
      "        [-0.1900, -0.1222],\n",
      "        [-0.7310,  1.0613],\n",
      "        [ 0.6899,  0.6949],\n",
      "        [ 0.2927,  1.2365],\n",
      "        [ 0.2696,  0.3718],\n",
      "        [ 0.4990,  0.7720],\n",
      "        [ 0.4736, -1.1566],\n",
      "        [-0.5583,  0.2864],\n",
      "        [ 0.1453,  0.7190],\n",
      "        [-0.4158, -0.4301],\n",
      "        [-0.5457, -0.9068],\n",
      "        [ 0.2722,  0.3440],\n",
      "        [ 0.8111,  0.4822],\n",
      "        [ 0.5239, -0.3180],\n",
      "        [ 0.3813, -0.6984],\n",
      "        [-0.4274,  0.7596],\n",
      "        [ 0.3771, -0.4795],\n",
      "        [ 0.2847,  0.2569],\n",
      "        [ 0.0890,  0.8790],\n",
      "        [ 0.2664,  0.4328],\n",
      "        [ 0.3066, -0.1774],\n",
      "        [ 1.3832,  0.6062],\n",
      "        [ 0.0786, -0.1544],\n",
      "        [-0.5718,  0.4252],\n",
      "        [ 0.0579,  0.5469],\n",
      "        [-0.2062, -1.3802]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[ 0.3489, -0.2584],\n",
      "        [ 0.7827,  1.3279],\n",
      "        [ 0.5237,  1.7052],\n",
      "        [-0.0142,  0.2398],\n",
      "        [-0.2829, -1.0727],\n",
      "        [-0.0375,  0.4571],\n",
      "        [-0.1900, -0.1222],\n",
      "        [-0.7310,  1.0613],\n",
      "        [ 0.6899,  0.6949],\n",
      "        [ 0.2927,  1.2365],\n",
      "        [ 0.2696,  0.3718],\n",
      "        [ 0.4990,  0.7720],\n",
      "        [ 0.4736, -1.1566],\n",
      "        [-0.5583,  0.2864],\n",
      "        [ 0.1453,  0.7190],\n",
      "        [-0.4158, -0.4301],\n",
      "        [-0.5457, -0.9068],\n",
      "        [ 0.2722,  0.3440],\n",
      "        [ 0.8111,  0.4822],\n",
      "        [ 0.5239, -0.3180],\n",
      "        [ 0.3813, -0.6984],\n",
      "        [-0.4274,  0.7596],\n",
      "        [ 0.3771, -0.4795],\n",
      "        [ 0.2847,  0.2569],\n",
      "        [ 0.0890,  0.8790],\n",
      "        [ 0.2664,  0.4328],\n",
      "        [ 0.3066, -0.1774],\n",
      "        [ 1.3832,  0.6062],\n",
      "        [ 0.0786, -0.1544],\n",
      "        [-0.5718,  0.4252],\n",
      "        [ 0.0579,  0.5469],\n",
      "        [-0.2062, -1.3802]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 0])\n",
      "X tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1854, 0.1854, 0.1854],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0389, 0.0534],\n",
      "        [0.1110, 1.3201, 2.4854,  ..., 0.0588, 0.0580, 0.0573],\n",
      "        ...,\n",
      "        [0.2010, 0.2543, 0.2464,  ..., 0.0000, 0.0000, 2.2848],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1020, 0.0000],\n",
      "        [0.0000, 0.0250, 0.0000,  ..., 0.8007, 0.0000, 0.4586]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[-0.3894, -0.7389],\n",
      "        [ 0.1104, -0.1577],\n",
      "        [ 1.1138, -0.5224],\n",
      "        [ 0.6190,  0.8552],\n",
      "        [ 0.4431,  0.0584],\n",
      "        [-0.2287,  0.0224],\n",
      "        [-0.1576, -0.0420],\n",
      "        [ 0.3626,  0.0132],\n",
      "        [ 0.4457, -0.2570],\n",
      "        [-0.3749,  0.3673],\n",
      "        [ 0.5602, -0.0384],\n",
      "        [ 0.1119,  0.1609],\n",
      "        [ 0.1240,  0.0703],\n",
      "        [ 0.0752,  0.3419],\n",
      "        [ 0.4001,  0.4879],\n",
      "        [-0.0667, -0.0750],\n",
      "        [ 0.3947, -0.0709],\n",
      "        [ 0.6920,  0.3587],\n",
      "        [-0.0796, -0.2546],\n",
      "        [-0.3941,  0.0617],\n",
      "        [ 0.6191,  0.2106],\n",
      "        [-0.2504,  1.3841],\n",
      "        [ 0.7717, -0.9035],\n",
      "        [ 0.1030,  0.2667],\n",
      "        [ 0.2803,  0.8692],\n",
      "        [-1.3004, -0.4080],\n",
      "        [ 0.4766, -0.8499],\n",
      "        [-0.5941, -0.0745],\n",
      "        [ 0.2977,  0.6322],\n",
      "        [ 0.3978,  0.2674],\n",
      "        [-0.2617, -0.3149],\n",
      "        [-0.3241, -0.5283]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[-0.3894, -0.7389],\n",
      "        [ 0.1104, -0.1577],\n",
      "        [ 1.1138, -0.5224],\n",
      "        [ 0.6190,  0.8552],\n",
      "        [ 0.4431,  0.0584],\n",
      "        [-0.2287,  0.0224],\n",
      "        [-0.1576, -0.0420],\n",
      "        [ 0.3626,  0.0132],\n",
      "        [ 0.4457, -0.2570],\n",
      "        [-0.3749,  0.3673],\n",
      "        [ 0.5602, -0.0384],\n",
      "        [ 0.1119,  0.1609],\n",
      "        [ 0.1240,  0.0703],\n",
      "        [ 0.0752,  0.3419],\n",
      "        [ 0.4001,  0.4879],\n",
      "        [-0.0667, -0.0750],\n",
      "        [ 0.3947, -0.0709],\n",
      "        [ 0.6920,  0.3587],\n",
      "        [-0.0796, -0.2546],\n",
      "        [-0.3941,  0.0617],\n",
      "        [ 0.6191,  0.2106],\n",
      "        [-0.2504,  1.3841],\n",
      "        [ 0.7717, -0.9035],\n",
      "        [ 0.1030,  0.2667],\n",
      "        [ 0.2803,  0.8692],\n",
      "        [-1.3004, -0.4080],\n",
      "        [ 0.4766, -0.8499],\n",
      "        [-0.5941, -0.0745],\n",
      "        [ 0.2977,  0.6322],\n",
      "        [ 0.3978,  0.2674],\n",
      "        [-0.2617, -0.3149],\n",
      "        [-0.3241, -0.5283]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1])\n",
      "X tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0977, 0.0977, 0.0977],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0887, 0.0887, 0.0887],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0887, 0.0887, 0.0000],\n",
      "        ...,\n",
      "        [0.3845, 0.3520, 0.3189,  ..., 0.0000, 0.4424, 0.2346],\n",
      "        [1.3264, 1.2601, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0977, 0.0000, 0.0000]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[ 5.5576e-01, -6.3305e-01],\n",
      "        [ 5.4951e-02,  1.6604e-01],\n",
      "        [ 1.0381e+00,  1.7691e-01],\n",
      "        [ 1.0014e-01,  1.0968e-01],\n",
      "        [ 6.7747e-01,  1.9385e-01],\n",
      "        [ 3.8520e-01, -1.7945e-01],\n",
      "        [ 1.6610e-03, -9.8268e-03],\n",
      "        [-2.9680e-01, -5.0104e-06],\n",
      "        [-1.3299e+00, -4.6375e-01],\n",
      "        [ 3.8514e-01, -1.5532e-01],\n",
      "        [-6.3647e-02, -1.7800e-01],\n",
      "        [ 7.4175e-02, -8.0406e-01],\n",
      "        [ 1.7045e-01,  1.0295e-01],\n",
      "        [ 5.1457e-01,  2.0238e-01],\n",
      "        [ 1.2961e+00,  5.0213e-01],\n",
      "        [ 3.7706e-01,  2.7977e-01],\n",
      "        [ 4.8286e-01,  7.3734e-01],\n",
      "        [ 2.9407e-01,  9.6530e-02],\n",
      "        [-5.5845e-02,  2.3253e-01],\n",
      "        [ 4.6935e-02,  3.7074e-01],\n",
      "        [ 1.4100e-01,  5.8831e-02],\n",
      "        [-2.7366e-01, -3.6000e-01],\n",
      "        [-1.1157e-01, -4.7780e-01],\n",
      "        [-8.8798e-01, -1.0381e-01],\n",
      "        [-1.5699e-01, -8.5225e-02],\n",
      "        [ 5.4953e-01,  6.0981e-01],\n",
      "        [ 2.0342e-01,  8.8423e-01],\n",
      "        [ 8.2993e-01,  9.4203e-02],\n",
      "        [ 4.5409e-01, -5.8659e-01],\n",
      "        [-9.8019e-01, -8.3596e-01],\n",
      "        [-9.7622e-02,  2.9482e-01],\n",
      "        [ 2.0268e-01, -4.9117e-01]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[ 5.5576e-01, -6.3305e-01],\n",
      "        [ 5.4951e-02,  1.6604e-01],\n",
      "        [ 1.0381e+00,  1.7691e-01],\n",
      "        [ 1.0014e-01,  1.0968e-01],\n",
      "        [ 6.7747e-01,  1.9385e-01],\n",
      "        [ 3.8520e-01, -1.7945e-01],\n",
      "        [ 1.6610e-03, -9.8268e-03],\n",
      "        [-2.9680e-01, -5.0104e-06],\n",
      "        [-1.3299e+00, -4.6375e-01],\n",
      "        [ 3.8514e-01, -1.5532e-01],\n",
      "        [-6.3647e-02, -1.7800e-01],\n",
      "        [ 7.4175e-02, -8.0406e-01],\n",
      "        [ 1.7045e-01,  1.0295e-01],\n",
      "        [ 5.1457e-01,  2.0238e-01],\n",
      "        [ 1.2961e+00,  5.0213e-01],\n",
      "        [ 3.7706e-01,  2.7977e-01],\n",
      "        [ 4.8286e-01,  7.3734e-01],\n",
      "        [ 2.9407e-01,  9.6530e-02],\n",
      "        [-5.5845e-02,  2.3253e-01],\n",
      "        [ 4.6935e-02,  3.7074e-01],\n",
      "        [ 1.4100e-01,  5.8831e-02],\n",
      "        [-2.7366e-01, -3.6000e-01],\n",
      "        [-1.1157e-01, -4.7780e-01],\n",
      "        [-8.8798e-01, -1.0381e-01],\n",
      "        [-1.5699e-01, -8.5225e-02],\n",
      "        [ 5.4953e-01,  6.0981e-01],\n",
      "        [ 2.0342e-01,  8.8423e-01],\n",
      "        [ 8.2993e-01,  9.4203e-02],\n",
      "        [ 4.5409e-01, -5.8659e-01],\n",
      "        [-9.8019e-01, -8.3596e-01],\n",
      "        [-9.7622e-02,  2.9482e-01],\n",
      "        [ 2.0268e-01, -4.9117e-01]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1])\n",
      "X tensor([[1.3385, 0.0000, 0.0000,  ..., 0.0000, 0.0468, 0.0000],\n",
      "        [0.7631, 1.4111, 0.9099,  ..., 0.0000, 0.9704, 0.0000],\n",
      "        [0.0000, 2.3829, 0.0000,  ..., 5.6111, 5.6111, 5.6111],\n",
      "        ...,\n",
      "        [0.2014, 0.2014, 0.2014,  ..., 0.9260, 0.9260, 0.9260],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2222, 0.2222, 0.2222],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.2222, 0.0000, 0.2222]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "X after tensor([[ 3.3587e-01, -1.0799e+00],\n",
      "        [-1.0146e+00, -1.4483e-01],\n",
      "        [ 2.0029e-01,  4.4005e-01],\n",
      "        [-5.2341e-01,  3.9724e-01],\n",
      "        [-2.7680e-01, -4.8286e-02],\n",
      "        [-1.4870e-01,  7.5865e-01],\n",
      "        [ 3.6348e-01,  4.9091e-01],\n",
      "        [-1.0716e-02,  2.4475e-01],\n",
      "        [ 7.1673e-01,  1.1062e+00],\n",
      "        [ 5.0762e-01, -5.1607e-01],\n",
      "        [ 5.6610e-02,  1.7534e-01],\n",
      "        [ 2.8377e-01,  8.2493e-01],\n",
      "        [ 8.8244e-01,  1.1408e+00],\n",
      "        [-2.9488e-01,  5.6452e-01],\n",
      "        [-4.2075e-01, -7.6907e-01],\n",
      "        [ 7.5952e-01,  1.0904e+00],\n",
      "        [ 4.5903e-01,  3.2507e-02],\n",
      "        [ 8.1004e-01, -2.2423e-01],\n",
      "        [-1.7587e+00,  6.3089e-01],\n",
      "        [ 2.3291e-01,  2.1801e-01],\n",
      "        [ 1.4108e-03, -5.0140e-01],\n",
      "        [ 6.9487e-02, -3.7868e-01],\n",
      "        [ 1.3543e-01, -9.5686e-02],\n",
      "        [ 1.3486e-01, -2.0937e-02],\n",
      "        [ 1.2433e-01, -8.0186e-02],\n",
      "        [ 3.3901e-01, -3.6364e-01],\n",
      "        [ 1.4755e-01, -1.7479e-01],\n",
      "        [ 1.3924e-01,  2.5483e-01],\n",
      "        [-3.5344e-01,  2.1516e-02],\n",
      "        [-1.0096e+00,  5.0843e-01],\n",
      "        [ 1.3772e-01, -6.2570e-01],\n",
      "        [ 9.3554e-01,  7.2071e-01]], grad_fn=<AddmmBackward>)\n",
      "pred tensor([[ 3.3587e-01, -1.0799e+00],\n",
      "        [-1.0146e+00, -1.4483e-01],\n",
      "        [ 2.0029e-01,  4.4005e-01],\n",
      "        [-5.2341e-01,  3.9724e-01],\n",
      "        [-2.7680e-01, -4.8286e-02],\n",
      "        [-1.4870e-01,  7.5865e-01],\n",
      "        [ 3.6348e-01,  4.9091e-01],\n",
      "        [-1.0716e-02,  2.4475e-01],\n",
      "        [ 7.1673e-01,  1.1062e+00],\n",
      "        [ 5.0762e-01, -5.1607e-01],\n",
      "        [ 5.6610e-02,  1.7534e-01],\n",
      "        [ 2.8377e-01,  8.2493e-01],\n",
      "        [ 8.8244e-01,  1.1408e+00],\n",
      "        [-2.9488e-01,  5.6452e-01],\n",
      "        [-4.2075e-01, -7.6907e-01],\n",
      "        [ 7.5952e-01,  1.0904e+00],\n",
      "        [ 4.5903e-01,  3.2507e-02],\n",
      "        [ 8.1004e-01, -2.2423e-01],\n",
      "        [-1.7587e+00,  6.3089e-01],\n",
      "        [ 2.3291e-01,  2.1801e-01],\n",
      "        [ 1.4108e-03, -5.0140e-01],\n",
      "        [ 6.9487e-02, -3.7868e-01],\n",
      "        [ 1.3543e-01, -9.5686e-02],\n",
      "        [ 1.3486e-01, -2.0937e-02],\n",
      "        [ 1.2433e-01, -8.0186e-02],\n",
      "        [ 3.3901e-01, -3.6364e-01],\n",
      "        [ 1.4755e-01, -1.7479e-01],\n",
      "        [ 1.3924e-01,  2.5483e-01],\n",
      "        [-3.5344e-01,  2.1516e-02],\n",
      "        [-1.0096e+00,  5.0843e-01],\n",
      "        [ 1.3772e-01, -6.2570e-01],\n",
      "        [ 9.3554e-01,  7.2071e-01]], grad_fn=<AddmmBackward>)\n",
      "pred shape torch.Size([32, 2])\n",
      "y tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14452/3348449233.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mepoch_train_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_train_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m# scheduler.step() # 更新学习率（调用官方动态学习率接口时使用）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14452/2558500294.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m  \u001b[1;31m# 初始化训练损失和正确率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 获取图片及其标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m#print(\"X\",X)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn    = nn.CrossEntropyLoss() # 创建损失函数\n",
    "epochs     = 40\n",
    "\n",
    "train_loss = []\n",
    "train_acc  = []\n",
    "test_loss  = []\n",
    "test_acc   = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 更新学习率（使用自定义学习率时使用）\n",
    "    adjust_learning_rate(optimizer, epoch, learn_rate)\n",
    "    \n",
    "    model.train()\n",
    "    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, optimizer)\n",
    "    # scheduler.step() # 更新学习率（调用官方动态学习率接口时使用）\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)\n",
    "    \n",
    "    train_acc.append(epoch_train_acc)\n",
    "    train_loss.append(epoch_train_loss)\n",
    "    test_acc.append(epoch_test_acc)\n",
    "    test_loss.append(epoch_test_loss)\n",
    "    \n",
    "    # 获取当前的学习率\n",
    "    lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    \n",
    "    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%, Test_loss:{:.3f}, Lr:{:.2E}')\n",
    "    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, \n",
    "                          epoch_test_acc*100, epoch_test_loss, lr))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#隐藏警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")               #忽略警告信息\n",
    "plt.rcParams['font.sans-serif']    = ['SimHei'] # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False      # 用来正常显示负号\n",
    "plt.rcParams['figure.dpi']         = 100        #分辨率\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(epochs_range, train_acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, test_acc, label='Test Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
    "plt.plot(epochs_range, test_loss, label='Test Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "\n",
    "classes = list(train_dataset.class_to_idx)\n",
    "\n",
    "def predict_one_image(image_path, model, transform, classes):\n",
    "    \n",
    "    test_img = Image.open(image_path).convert('RGB')\n",
    "    # plt.imshow(test_img)  # 展示预测的图片\n",
    "\n",
    "    test_img = transform(test_img)\n",
    "    img = test_img.to(device).unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    output = model(img)\n",
    "\n",
    "    _,pred = torch.max(output,1)\n",
    "    pred_class = classes[pred]\n",
    "    print(f'预测结果是：{pred_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测训练集中的某张照片\n",
    "predict_one_image(image_path='./5-data/test/adidas/1.jpg', \n",
    "                  model=model, \n",
    "                  transform=train_transforms, \n",
    "                  classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存\n",
    "PATH = './model.pth'  # 保存的参数文件名\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "# 将参数加载到model当中\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
